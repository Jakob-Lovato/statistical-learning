# -*- coding: utf-8 -*-
"""Stat 760 HW 8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fd2Vl9fmSAGKE7IPaqvy-dLWsIkDhjHe

**Question 1**
"""

import torch
import torchvision
import pandas as pd
import numpy as np

#import data
data = pd.read_csv("/content/housing.csv")
data

set(data['ocean_proximity'])

#convert categorical variable
ocean = list(set(data['ocean_proximity']))
ocean

X = data
X.replace(ocean, [0, 1, 2, 3, 4], inplace=True)
X = X.dropna(axis = 0, how = 'any')
X

#standardize data
X = (X - X.mean()) / X.std()

X

Y

Y = X['median_house_value'].to_numpy()
X = X.drop('median_house_value', axis=1).to_numpy()

#check to make sure no 'na' values in data
pd.isna(X).sum()

X = torch.tensor(X, dtype = torch.float)
Y = torch.tensor(Y, dtype = torch.float).view(-1, 1)

lr = 0.1
w = torch.tensor([2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0], requires_grad = True)
b = torch.tensor(5.0, requires_grad = True)

#define functions
def loss_func(yhat, y):
  squared_diffs = (yhat - y)**2
  return squared_diffs.mean()

def forward(x, w, b):
  return torch.matmul(x, w) + b

import torch.optim as optim
import matplotlib.pyplot as plt

#t_un = t_u*0.1
params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad=True)
learning_rate = 1e-2
optimizer = optim.SGD([params], lr=learning_rate)
 
#t_p = model(t_un, *params)
p = forward(X, params[0:9], params[9])
loss = loss_func(p, Y)
 
optimizer.zero_grad()
loss.backward()
optimizer.step()
 
params

def training_loop(n_epochs, optimizer, params, X, Y):
  for epoch in range(n_epochs):
    p = forward(X, params[0:9], params[9])
    loss = loss_func(p, Y)

    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    if epoch%40 ==0:
      print('Epoch %d, Loss %f' %(epoch, float(loss)))
  
  return params

params = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0], requires_grad=True)
learning_rate = 1e-2
optimizer = optim.SGD([params], lr=learning_rate)

training_loop(
    n_epochs = 400,
    optimizer = optimizer,
    params = params,
    X = X,
    Y = Y)

"""**Question 2**"""

#import libraries
from torchvision import datasets, transforms
import torch
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt

data_path = '/Users/jakoblovato/Desktop/Stat 760/HW 8/CIFAR10'
cifar10 = datasets.CIFAR10(data_path, train=True, download=True)
cifar10_val = datasets.CIFAR10(data_path, train=False, download=True)
classes = ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

tensor_cifar10 = datasets.CIFAR10(data_path, train=True, download=False, transform=transforms.ToTensor())
tensor_cifar10_val = datasets.CIFAR10(data_path, train=False, download=False, transform=transforms.ToTensor())

#standardize images
imgs = torch.stack([img_t for img_t, _ in tensor_cifar10], dim=3)
imgs.shape

imgs.view(3,-1).mean(dim=1)

imgs.view(3,-1).std(dim=1)

transformed_cifar10 = datasets.CIFAR10(data_path, train=True, download=False, 
                                       transform=transforms.Compose([transforms.ToTensor(), 
                                                                     transforms.Normalize((0.4915, 0.4822, 0.4465), 
                                                                                          (0.2470, 0.2435, 0.2616))
                                                                     ]))
len(transformed_cifar10)

imgs = torch.stack([img_t for img_t, _ in tensor_cifar10_val], dim=3)
imgs.shape

imgs.view(3,-1).mean(dim=1)

imgs.view(3,-1).std(dim=1)

transformed_cifar10_val = datasets.CIFAR10(data_path, train=False, download=False, 
                                       transform=transforms.Compose([transforms.ToTensor(), 
                                                                     transforms.Normalize((0.4942, 0.4851, 0.4504), 
                                                                                          (0.2467, 0.2429, 0.2616))
                                                                     ]))

#only include 7 classes
label_map = {1: 0, 3: 1, 5: 2, 6: 3, 7: 4, 8: 5, 9: 6}
class_names = ['automobile', 'cat', 'dog', 'frog', 'horse', 'ship', 'truck']
cifar7 = [(img, label_map[label]) for img, label in transformed_cifar10 if label in [1,3,5,6,7,8,9]]
cifar7_val = [(img, label_map[label]) for img, label in transformed_cifar10_val if label in [1,3,5,6,7,8,9]]

#training
train_loader = torch.utils.data.DataLoader(cifar7, batch_size=64,
                                           shuffle=True)
 
model = nn.Sequential(
           nn.Linear(3072, 512),
           nn.Tanh(),
           nn.Linear(512, 7)
           )
 
learning_rate = 1e-2
 
optimizer = optim.SGD(model.parameters(), lr=learning_rate)
 
loss_fn = nn.CrossEntropyLoss()
 
n_epochs = 100
 
for epoch in range(n_epochs):
  for imgs, labels in train_loader:
    batch_size = imgs.shape[0]
    outputs = model(imgs.view(batch_size, -1))
    loss = loss_fn(outputs, labels)
 
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

  print("Epoch: %d, Loss: %f" % (epoch, float(loss)))

class_names

#model accuracy
val_loader = torch.utils.data.DataLoader(cifar7_val, batch_size=64, shuffle=False)

correct = 0
total = 0
correct_class = {class_names[0]:0, class_names[1]:0, class_names[2]:0, class_names[3]:0, class_names[4]:0, class_names[5]:0, class_names[6]:0}
total_class = {class_names[0]:0, class_names[1]:0, class_names[2]:0, class_names[3]:0, class_names[4]:0, class_names[5]:0, class_names[6]:0}

with torch.no_grad():
  for imgs, labels in val_loader:
    batch_size = imgs.shape[0]
    outputs = model(imgs.view(batch_size, -1))
    _, predicted = torch.max(outputs, dim=1)
    for lab, pred in zip(labels, predicted):
      if lab == pred:
        correct_class[class_names[lab]] += 1
      total_class[class_names[lab]] += 1
    total += labels.shape[0]
    correct += int((predicted == labels).sum())

print("Total Accuracy:")
print(correct / total)
for i in range(7):
  print(f"Accuracy for {class_names[i]}:")
  print(correct_class[class_names[i]] / total_class[class_names[i]])